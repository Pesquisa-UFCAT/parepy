{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from parepy_toolbox.distributions import non_normal_approach_normal\n",
    "\n",
    "# params_normal = {'loc': 0, 'scale': 1}\n",
    "# result_normal = non_normal_approach_normal(1.3065, 'normal', params_normal)\n",
    "# print(result_normal)\n",
    "\n",
    "# params_gumbel_max = {'loc': 0.887487, 'scale': 5.1302}\n",
    "# result_gumbel_max = non_normal_approach_normal(1.3065, 'gumbel max', params_gumbel_max)\n",
    "# print(result_gumbel_max)\n",
    "\n",
    "# params_log_normal = {'loc': 0.887487, 'scale': 5.1302}\n",
    "# result_log_normal = non_normal_approach_normal(1.3065, 'log normal', params_log_normal)\n",
    "# print(result_log_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj(x, none_variable):\n",
    "    simga_y = x[0]\n",
    "    w = x[1]\n",
    "    m = x[2]\n",
    "    return simga_y * w - m\n",
    "\n",
    "def grad_obj(x, none_variable):\n",
    "    sigma_y = x[0]\n",
    "    w = x[1]\n",
    "    m = x[2]\n",
    "    grad_g = [w, sigma_y, -1]\n",
    "    return grad_g\n",
    "\n",
    "def deterministic_algorithm_structural_analysis(setup: dict):\n",
    "    \n",
    "    mu = [40., 50., 1000.]\n",
    "    sigma = [5., 2.5, 200.]\n",
    "    tol = 1e-6\n",
    "    max_iter = 20\n",
    "    beta_list = [10000]\n",
    "    error = 1000\n",
    "    iter = 0\n",
    "    step = 1\n",
    "\n",
    "    x = np.transpose(np.array([mu.copy()]))\n",
    "    mu = x.copy()\n",
    "    jacobian_xy = np.diag(sigma)\n",
    "    jacobian_xy_trans = np.transpose(jacobian_xy)\n",
    "    jacobian_yx = np.linalg.inv(jacobian_xy)\n",
    "    y = jacobian_yx @ (x - mu)\n",
    "    x = jacobian_xy @ y + mu\n",
    "\n",
    "    while (error > tol and iter < max_iter):\n",
    "        beta = np.linalg.norm(y)\n",
    "        beta_list.append(beta)\n",
    "        g_y = obj(x.flatten().tolist(), None)\n",
    "        grad_g_x = grad_obj(x.flatten().tolist(), None)\n",
    "        grad_g_y = np.dot(jacobian_xy_trans, np.transpose(np.array([grad_g_x])))\n",
    "        num = (np.transpose(grad_g_y) @ y - g_y)\n",
    "        norm = np.linalg.norm(grad_g_y)\n",
    "        norm2 = norm ** 2\n",
    "        #alpha = grad_g_y / norm\n",
    "        #aux = g_y / norm\n",
    "        #y = -alpha * (beta + aux)\n",
    "        print(grad_g_y, y, g_y, num, norm2)\n",
    "        d = num / norm2 @ grad_g_y - y\n",
    "        y += + step * d\n",
    "        error = np.abs(beta_list[iter + 1] - beta_list[iter])\n",
    "        iter += 1\n",
    "        x = jacobian_xy @ y + mu\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 250.]\n",
      " [ 100.]\n",
      " [-200.]] [[0.]\n",
      " [0.]\n",
      " [0.]] 1000.0 [[-1000.]] 112500.00000000001\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 21\u001b[0m\n\u001b[0;32m      8\u001b[0m setup \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      9\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtolerance\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1e-6\u001b[39m, \n\u001b[0;32m     10\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax iterations\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname simulation\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     18\u001b[0m         }\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Call algorithm\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m beta \u001b[38;5;241m=\u001b[39m \u001b[43mdeterministic_algorithm_structural_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43msetup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(beta)\n",
      "Cell \u001b[1;32mIn[3], line 46\u001b[0m, in \u001b[0;36mdeterministic_algorithm_structural_analysis\u001b[1;34m(setup)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m#alpha = grad_g_y / norm\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m#aux = g_y / norm\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#y = -alpha * (beta + aux)\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(grad_g_y, y, g_y, num, norm2)\n\u001b[1;32m---> 46\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[43mnum\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnorm2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgrad_g_y\u001b[49m \u001b[38;5;241m-\u001b[39m y\n\u001b[0;32m     47\u001b[0m y \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m+\u001b[39m step \u001b[38;5;241m*\u001b[39m d\n\u001b[0;32m     48\u001b[0m error \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(beta_list[\u001b[38;5;28miter\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m beta_list[\u001b[38;5;28miter\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 1)"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "f = {'type': 'normal', 'parameters': {'mean': 40, 'sigma': 5.}, 'stochastic variable': False}\n",
    "p = {'type': 'normal', 'parameters': {'mean': 50, 'sigma': 2.5}, 'stochastic variable': False}\n",
    "w = {'type': 'normal', 'parameters': {'mean': 1000, 'sigma': 200}, 'stochastic variable': False}\n",
    "var = [f, p, w]\n",
    "\n",
    "# PAREpy setup\n",
    "setup = {\n",
    "                'tolerance': 1e-6, \n",
    "                'max iterations': 20,\n",
    "                'numerical model': 'fosm', \n",
    "                'variables settings': var, \n",
    "                'number of state limit functions or constraints': 1, \n",
    "                'none variable': None,\n",
    "                'objective function': obj,\n",
    "                'gradient objective function': grad_obj,\n",
    "                'name simulation': None,\n",
    "        }\n",
    "\n",
    "# Call algorithm\n",
    "beta = deterministic_algorithm_structural_analysis(setup)\n",
    "print(beta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
