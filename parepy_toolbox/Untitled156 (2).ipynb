{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy as sc\n",
        "from typing import Optional"
      ],
      "metadata": {
        "id": "5sWUbSe1jK4P"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MpdLtTY_hgko"
      },
      "outputs": [],
      "source": [
        "def std_matrix(std: list) -> tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Extract D matrix and D^-1 matrix from a list of variables. Used in Y to X or X to Y transformation.\n",
        "\n",
        "    :param std: Standard deviation parameters.\n",
        "\n",
        "    return: output[0] = D matrix, output[1] = D^-1 matrix\n",
        "    \"\"\"\n",
        "\n",
        "    dneq = np.zeros((len(std), len(std)))\n",
        "    dneq1 = np.zeros((len(std), len(std)))\n",
        "    for i, sigma in enumerate(std):\n",
        "        dneq[i, i] = sigma\n",
        "        dneq1[i, i] = 1 / sigma\n",
        "\n",
        "    return dneq, dneq1\n",
        "\n",
        "\n",
        "def mu_matrix(mean: list) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Extract mean matrix from a list of variables. Used in Y to X or X to Y transformation.\n",
        "\n",
        "    :param mu: Mean parameters.\n",
        "\n",
        "    return: Mean matrix\n",
        "    \"\"\"\n",
        "\n",
        "    mu_neq = np.zeros((len(mean), 1))\n",
        "    for i, mu in enumerate(mean):\n",
        "        mu_neq[i, 0] = mu\n",
        "\n",
        "    return mu_neq\n",
        "\n",
        "def x_to_y(x: np.ndarray, dneq1: np.ndarray, mu_neq: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Transforms a vector of random variables from the X space to the Y space.\n",
        "\n",
        "    :param x: Random variables in the X space.\n",
        "    :param dneq1: D^-1 matrix.\n",
        "    :param mu_neq: Mean matrix.\n",
        "\n",
        "    :return: Transformed random variables in the Y space.\n",
        "    \"\"\"\n",
        "\n",
        "    return dneq1 @ (x - mu_neq)\n",
        "\n",
        "\n",
        "def y_to_x(y: np.ndarray, dneq: np.ndarray, mu_neq: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Transforms a vector of random variables from the Y space to the X space.\n",
        "\n",
        "    :param y: Random variables in the Y space.\n",
        "    :param dneq: D matrix.\n",
        "    :param mu_neq: Mean matrix.\n",
        "\n",
        "    :return: Transformed random variables in the X space.\n",
        "    \"\"\"\n",
        "\n",
        "    return dneq @ y + mu_neq\n",
        "\n",
        "\n",
        "def convert_params_to_scipy(dist: str, parameters: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Convert user-provided distribution parameters to the format required by \"scipy.stats\".\n",
        "\n",
        "    :param parameters: Original distribution parameters.\n",
        "\n",
        "    :return: Transformed parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    if dist.lower() == 'uniform':\n",
        "        parameters_scipy = {'loc': parameters['min'], 'scale': parameters['max'] - parameters['min']}\n",
        "    elif dist.lower() == 'normal':\n",
        "        parameters_scipy = {'loc': parameters['mean'], 'scale': parameters['std']}\n",
        "    elif dist.lower() == 'lognormal':\n",
        "        epsilon = np.sqrt(np.log(1 + (parameters['std'] / parameters['mean'])**2))\n",
        "        lambdaa = np.log(parameters['mean']) - 0.50 * epsilon**2\n",
        "        # lognorm_dist = np.random.lognormal(lambdaa, epsilon, 100000)\n",
        "        # s, l, sca = sc.stats.lognorm.fit(lognorm_dist)\n",
        "        # parameters_scipy = {'s': s, 'loc': l, 'scale': sca}\n",
        "        parameters_scipy = {'lambda': lambdaa, 'epsilon': epsilon}\n",
        "    elif dist.lower() == 'gumbel max':\n",
        "        euler_gamma = 0.5772156649015329\n",
        "        alpha = parameters['std'] * np.sqrt(6) / np.pi\n",
        "        beta = parameters['mean'] - alpha * euler_gamma\n",
        "        parameters_scipy = {'loc': beta, 'scale': alpha}\n",
        "\n",
        "    return parameters_scipy\n",
        "\n",
        "\n",
        "def normal_tail_approximation(dist: str, parameters_scipy: dict, x: float) -> tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Converts non-normal distributions to normal approximations while preserving their statistical properties in x point.\n",
        "\n",
        "    :param dist: Type of distribution. Supported values: 'uniform', 'normal', 'lognormal', 'gumbel max', 'gumbel min', 'triangular', 'gamma'.\n",
        "    :param parameters_scipy: Distribution parameters according scipy.stats documentation.\n",
        "    :param x: Project point.\n",
        "\n",
        "    return: output[0] = Mean of the normal approximation at point x, output[1] = standard deviation of the normal approximation at point x.\n",
        "    \"\"\"\n",
        "\n",
        "    if dist.lower() == 'uniform':\n",
        "        loc = parameters_scipy['loc']\n",
        "        scale = parameters_scipy['scale'] - parameters_scipy['loc']\n",
        "        z_aux = sc.stats.uniform.cdf(x, loc=loc, scale=scale)\n",
        "        z = sc.stats.norm.ppf(z_aux, loc=0, scale=1)\n",
        "        num = sc.stats.norm.pdf(z, loc=0, scale=1)\n",
        "        den = sc.stats.uniform.pdf(x, loc=loc, scale=scale)\n",
        "        std_eq = num / den\n",
        "        mean_eq = x - std_eq * z\n",
        "    elif dist.lower() == 'normal':\n",
        "        mean_eq = parameters_scipy['loc']\n",
        "        std_eq = parameters_scipy['scale']\n",
        "    elif dist.lower() == 'lognormal':\n",
        "        epsilon = parameters_scipy['epsilon']\n",
        "        lambdaa = parameters_scipy['lambda']\n",
        "        # mean_eq = x * (1 - np.log(x) + lambdaa)\n",
        "        # std_eq = x * epsilon\n",
        "        # s = parameters_scipy['s']\n",
        "        # loc = parameters_scipy['loc']\n",
        "        # scale = parameters_scipy['scale']\n",
        "        s = parameters_scipy['epsilon']\n",
        "        loc = 0\n",
        "        scale = np.exp(parameters_scipy['lambda'])\n",
        "        z_aux = sc.stats.lognorm.cdf(x, s=s, loc=loc, scale=scale)\n",
        "        z = sc.stats.norm.ppf(z_aux, loc=0, scale=1)\n",
        "        num = sc.stats.norm.pdf(z, loc=0, scale=1)\n",
        "        den = sc.stats.lognorm.pdf(x, s=s, loc=loc, scale=scale)\n",
        "        std_eq = num / den\n",
        "        mean_eq = x - std_eq * z\n",
        "    elif dist.lower() == 'gumbel max':\n",
        "        loc = parameters_scipy['loc']\n",
        "        scale = parameters_scipy['scale']\n",
        "        z_aux = sc.stats.gumbel_r.cdf(x, loc=loc, scale=scale)\n",
        "        z = sc.stats.norm.ppf(z_aux, loc=0, scale=1)\n",
        "        num = sc.stats.norm.pdf(z, loc=0, scale=1)\n",
        "        den = sc.stats.gumbel_r.pdf(x, loc=loc, scale=scale)\n",
        "        std_eq = num / den\n",
        "        mean_eq = x - std_eq * z\n",
        "\n",
        "    return mean_eq, std_eq\n",
        "\n",
        "\n",
        "def obj(x):\n",
        "    return x[0] - (x[1] + x[2])\n",
        "\n",
        "\n",
        "def deterministic_algorithm_structural_analysis_(n_iter: int, variables: list, x0: list, args: Optional[tuple] = None) -> tuple[float, float]:\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "\n",
        "    y_old_list = []\n",
        "    y_list = []\n",
        "    beta_list = []\n",
        "    x = x0.copy()\n",
        "    for i in range(n_iter):\n",
        "        mu_eq = []\n",
        "        sigma_eq = []\n",
        "\n",
        "        # Convert variables in Normal pattern\n",
        "        for i, var in enumerate(variables):\n",
        "            mean = var['parameters']['mean']\n",
        "            std = var['parameters']['std']\n",
        "            # print('mean: ', mean)\n",
        "            # print('std: ', std)\n",
        "            paras_scipy = convert_params_to_scipy(var['type'], var['parameters'])\n",
        "            m, s = normal_tail_approximation(var['type'], paras_scipy, x[i])\n",
        "            # print(\"paras_scipy :\", paras_scipy)\n",
        "            # print(\"m: \", m)\n",
        "            # print(\"s: \", s)\n",
        "            mu_eq.append(m)\n",
        "            sigma_eq.append(s)\n",
        "\n",
        "        # Numerical differentiation g(x)\n",
        "        H = 1E-12\n",
        "        g_diff_x_p = []\n",
        "        g_diff_x_r = []\n",
        "        for i in range(len(variables)):\n",
        "            x_aux_p = x.copy()\n",
        "            x_aux_p[i] += H\n",
        "            x_aux_r = x.copy()\n",
        "            x_aux_r[i] -= H\n",
        "            # print(\"x_aux_p: \", x_aux_p)\n",
        "            # print(\"x_aux_r: \", x_aux_r)\n",
        "            g_diff_x_p.append(obj(x_aux_p))\n",
        "            g_diff_x_r.append(obj(x_aux_r))\n",
        "        g_diff_x = [(g_diff_x_p[i] - g_diff_x_r[i]) / (2 * H) for i in range(len(variables))]\n",
        "        # print(\"g_diff_x: \", g_diff_x)\n",
        "\n",
        "        # yk and g(y)\n",
        "        dneq, dneq1 = std_matrix(sigma_eq)\n",
        "        mu_vars = mu_matrix(mu_eq)\n",
        "        print(\"dneq: \", dneq)\n",
        "        print(\"dneq1: \", dneq1)\n",
        "        print(\"mu_vars: \", mu_vars)\n",
        "        y_old = x_to_y(np.array(x).reshape(-1, 1), dneq1, mu_vars)\n",
        "        y_old_list.append(y_old)\n",
        "        g_y = obj(y_old)\n",
        "        # print(g_y)\n",
        "\n",
        "        # Numerical differentiation g(y)\n",
        "        g_diff_y = np.matrix_transpose(dneq) @ np.array(g_diff_x).reshape(-1, 1)\n",
        "        print('y old: ', y_old)\n",
        "        print('gdiffyut: ' , np.matrix_transpose(g_diff_y))\n",
        "        # Update y (HLRF algorithm)\n",
        "        num = (np.matrix_transpose(g_diff_y) @ y_old - g_y)\n",
        "        norm = np.linalg.norm(g_diff_y)\n",
        "        norm2 = norm ** 2\n",
        "        # print(\"num: \", num)\n",
        "        # print(\"norm: \", norm)\n",
        "        # print(\"norm2: \", norm2)\n",
        "        # print(\"gdiffy: \", g_diff_y)\n",
        "        y = g_diff_y @ (num / norm2)\n",
        "        x = y_to_x(y, dneq, mu_vars)\n",
        "        print(\"ynew: \", y)\n",
        "        print(\"xnew: \", x)\n",
        "\n",
        "        # grad y\n",
        "        y_list.append(y)\n",
        "        beta = np.linalg.norm(y)\n",
        "        print(\"beta: \", beta)\n",
        "        beta_list.append(beta)\n",
        "\n",
        "    return 0, 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [2.4105, 1.1041, 1.3065]\n",
        "r = {'type': 'lognormal', 'parameters': {'mean': 3.3289, 'std': 0.4328}}\n",
        "d = {'type': 'normal', 'parameters': {'mean': 1.0500, 'std': 0.1050}}\n",
        "l = {'type': 'gumbel max', 'parameters': {'mean': 1.0000, 'std': 0.2500}}\n",
        "var = [r, d, l]\n",
        "\n",
        "deterministic_algorithm_structural_analysis_(5, var, x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y286lZ0AjFfM",
        "outputId": "b8e17752-da7b-48f6-9034-500daf2c3ffa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dneq:  [[0.31208376 0.         0.        ]\n",
            " [0.         0.105      0.        ]\n",
            " [0.         0.         0.35340127]]\n",
            "dneq1:  [[3.20426793 0.         0.        ]\n",
            " [0.         9.52380952 0.        ]\n",
            " [0.         0.         2.82964464]]\n",
            "mu_vars:  [[3.16842551]\n",
            " [1.05      ]\n",
            " [0.87303406]]\n",
            "y old:  [[-2.42859642]\n",
            " [ 0.5152381 ]\n",
            " [ 1.22655458]]\n",
            "gdiffyut:  [[ 0.31211151 -0.10500933 -0.35343268]]\n",
            "ynew:  [[ 3.9118888 ]\n",
            " [-1.31614768]\n",
            " [-4.42979294]]\n",
            "xnew:  [[ 4.3892625 ]\n",
            " [ 0.91180449]\n",
            " [-0.69246038]]\n",
            "beta:  6.054600252445353\n",
            "dneq:  [[0.56827113 0.         0.        ]\n",
            " [0.         0.105      0.        ]\n",
            " [0.         0.                nan]]\n",
            "dneq1:  [[1.75972338 0.         0.        ]\n",
            " [0.         9.52380952 0.        ]\n",
            " [0.         0.                nan]]\n",
            "mu_vars:  [[3.13876011]\n",
            " [1.05      ]\n",
            " [       nan]]\n",
            "y old:  [[nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "gdiffyut:  [[ 0.56832165 -0.10500933         nan]]\n",
            "ynew:  [[nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "xnew:  [[nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "beta:  nan\n",
            "dneq:  [[  nan 0.    0.   ]\n",
            " [0.    0.105 0.   ]\n",
            " [0.    0.      nan]]\n",
            "dneq1:  [[       nan 0.         0.        ]\n",
            " [0.         9.52380952 0.        ]\n",
            " [0.         0.                nan]]\n",
            "mu_vars:  [[ nan]\n",
            " [1.05]\n",
            " [ nan]]\n",
            "y old:  [[nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "gdiffyut:  [[nan nan nan]]\n",
            "ynew:  [[nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "xnew:  [[nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "beta:  nan\n",
            "dneq:  [[  nan 0.    0.   ]\n",
            " [0.    0.105 0.   ]\n",
            " [0.    0.      nan]]\n",
            "dneq1:  [[       nan 0.         0.        ]\n",
            " [0.         9.52380952 0.        ]\n",
            " [0.         0.                nan]]\n",
            "mu_vars:  [[ nan]\n",
            " [1.05]\n",
            " [ nan]]\n",
            "y old:  [[nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "gdiffyut:  [[nan nan nan]]\n",
            "ynew:  [[nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "xnew:  [[nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "beta:  nan\n",
            "dneq:  [[  nan 0.    0.   ]\n",
            " [0.    0.105 0.   ]\n",
            " [0.    0.      nan]]\n",
            "dneq1:  [[       nan 0.         0.        ]\n",
            " [0.         9.52380952 0.        ]\n",
            " [0.         0.                nan]]\n",
            "mu_vars:  [[ nan]\n",
            " [1.05]\n",
            " [ nan]]\n",
            "y old:  [[nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "gdiffyut:  [[nan nan nan]]\n",
            "ynew:  [[nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "xnew:  [[nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "beta:  nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-b7119a9e3cd6>:138: RuntimeWarning: invalid value encountered in divide\n",
            "  std_eq = num / den\n",
            "<ipython-input-2-b7119a9e3cd6>:13: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  dneq[i, i] = sigma\n",
            "<ipython-input-2-b7119a9e3cd6>:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  dneq1[i, i] = 1 / sigma\n",
            "<ipython-input-2-b7119a9e3cd6>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  mu_neq[i, 0] = mu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import lognorm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mu = 3.3289\n",
        "sigma = 0.4328\n",
        "n = 100000\n",
        "\n",
        "epsilon = np.sqrt(np.log(sigma**2 / mu**2 + 1))\n",
        "lambdaa = np.log(mu) - epsilon**2 / 2\n",
        "print(epsilon, lambdaa)\n",
        "\n",
        "lognorm_dist = np.random.lognormal(lambdaa, epsilon, n)\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10, 3))  # figsize ajusta o tamanho\n",
        "ax.hist(lognorm_dist, density=True, bins='auto', histtype='stepfilled', alpha=0.2, color='blue')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "ywUn7pcv7fQG",
        "outputId": "4260f13d-6c90-4384-8576-b4db7decac1a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12946847734303465 1.1942608757781785\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import lognorm\n",
        "s, l, sc = lognorm.fit(lognorm_dist)\n",
        "print(s, l, sc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFPsPbdLOFT8",
        "outputId": "5eba0304-f3a0-4417-c7b3-8972d6227a4c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.128635834639969 -0.020858406573421754 3.320803103352192\n"
          ]
        }
      ]
    }
  ]
}